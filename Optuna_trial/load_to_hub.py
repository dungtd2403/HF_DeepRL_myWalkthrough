import gym

from stable_baselines3 import PPO,A2C
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.env_util import make_vec_env

from huggingface_sb3 import package_to_hub

# PLACE the variables you've just defined two cells above
# Define the name of the environment
env_id = "CartPole-v1"

model = A2C(
    policy="MlpPolicy",
    env= env_id,
    gamma=0.99,
    n_steps= 500,
    learning_rate= 0.001,
    max_grad_norm= 1.2
)

# Define the model architecture we used
model_architecture = "A2C"
model_name = 'trial68'
## Define a repo_id
## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2
## CHANGE WITH YOUR REPO ID
repo_id = "dungtd2403/CartPole-v1" # Change with your repo id, you can't push with mine ðŸ˜„

## Define the commit message
commit_message = "Upload A2C CartPole-v1 trained agent - before finetunning"

# Create the evaluation env
eval_env = DummyVecEnv([lambda: gym.make(env_id)])

# PLACE the package_to_hub function you've just filled here
package_to_hub(model=model, # Our trained model
               model_name=model_name, # The name of our trained model 
               model_architecture=model_architecture, # The model architecture we used: in our case PPO
               env_id=env_id, # Name of the environment
               eval_env=eval_env, # Evaluation Environment
               repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2
               commit_message=commit_message)
